// IPFS Upload service using Lighthouse
import lighthouse from '@lighthouse-web3/sdk'
import { generateMemoryMetadata, createMetadataFile, generateMemoryPreview, MemoryUploadData, validateMetadata } from './metadata'
import { useNotification } from '@blockscout/app-sdk'

const LIGHTHOUSE_API_KEY = process.env.NEXT_PUBLIC_LIGHTHOUSE_API_KEY || '2990024c.40dc50bbe7b94ffdb01c97f9943ae55d'

export interface UploadProgress {
  stage: 'preparing' | 'processing' | 'uploading' | 'complete' | 'error'
  progress: number
  message: string
  cid?: string
  error?: string
}

export interface UploadResult {
  success: boolean
  cid?: string
  ipfsUrl?: string
  gatewayUrl?: string
  metadataUrl?: string
  sceneUrl?: string
  error?: string
}

// Create a virtual file system for upload
class VirtualFileSystem {
  private files: Map<string, File | Blob> = new Map()

  addFile(path: string, content: File | Blob | string) {
    if (typeof content === 'string') {
      content = new Blob([content], { type: 'text/plain' })
    }
    this.files.set(path, content)
  }

  getFiles(): Map<string, File | Blob> {
    return this.files
  }

  clear() {
    this.files.clear()
  }
}

// Process video file to generate 3D scene (simulated for demo)
async function processVideoTo3D(videoFile: File, onProgress?: (progress: number) => void): Promise<{ sceneBlob: Blob; previewBlob: Blob }> {
  // Simulate 3D processing with progress updates
  const steps = 10
  for (let i = 0; i <= steps; i++) {
    await new Promise(resolve => setTimeout(resolve, 200))
    onProgress?.(i / steps * 100)
  }

  // For demo, create placeholder files
  // In production, this would call your 3D processing pipeline
  const sceneData = `ply
format ascii 1.0
comment Generated by Memora from video: ${videoFile.name}
element vertex 8
property float x
property float y
property float z
property uchar red
property uchar green
property uchar blue
end_header
-1.0 -1.0 -1.0 255 0 0
1.0 -1.0 -1.0 0 255 0
1.0 1.0 -1.0 0 0 255
-1.0 1.0 -1.0 255 255 0
-1.0 -1.0 1.0 255 0 255
1.0 -1.0 1.0 0 255 255
1.0 1.0 1.0 128 128 128
-1.0 1.0 1.0 255 255 255`

  const sceneBlob = new Blob([sceneData], { type: 'model/ply' })

  // Create a simple preview image (base64 encoded 1x1 pixel PNG)
  const previewData = 'iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mNkYPhfDwAChwGA60e6kgAAAABJRU5ErkJggg=='
  const previewBlob = new Blob([Uint8Array.from(atob(previewData), c => c.charCodeAt(0))], { type: 'image/png' })

  return { sceneBlob, previewBlob }
}

// Upload memory to IPFS with metadata
export async function uploadMemoryToIPFS(
  uploadData: MemoryUploadData,
  onProgress?: (progress: UploadProgress) => void
): Promise<UploadResult> {
  const fs = new VirtualFileSystem()

  try {
    // Stage 1: Preparing files
    onProgress?.({
      stage: 'preparing',
      progress: 10,
      message: 'Preparing memory files...'
    })

    // Generate memory text file
    const memoryText = generateMemoryPreview(uploadData)
    fs.addFile('memory.txt', memoryText)

    // Stage 2: Processing video to 3D
    onProgress?.({
      stage: 'processing',
      progress: 20,
      message: 'Converting video to 3D scene...'
    })

    const { sceneBlob, previewBlob } = await processVideoTo3D(
      uploadData.videoFile,
      (progress) => {
        onProgress?.({
          stage: 'processing',
          progress: 20 + (progress * 0.5), // 20-70%
          message: `Processing 3D scene... ${Math.round(progress)}%`
        })
      }
    )

    fs.addFile('scene.ply', sceneBlob)
    fs.addFile('preview.png', previewBlob)

    // Stage 3: Generate metadata (temporary CID for initial metadata)
    onProgress?.({
      stage: 'preparing',
      progress: 75,
      message: 'Generating NFT metadata...'
    })

    // We'll need to upload twice - first to get CID, then with proper metadata
    // For now, use placeholder CID
    const tempCid = 'QmTempCidWillBeReplaced'
    const metadata = generateMemoryMetadata(uploadData, tempCid)
    
    // Validate metadata
    const validation = validateMetadata(metadata)
    if (!validation.isValid) {
      throw new Error(`Metadata validation failed: ${validation.errors.join(', ')}`)
    }

    const metadataJson = createMetadataFile(metadata)
    fs.addFile('metadata.json', metadataJson)

    // Stage 4: Upload to IPFS
    onProgress?.({
      stage: 'uploading',
      progress: 80,
      message: 'Uploading to IPFS via Lighthouse...'
    })

    // Convert virtual filesystem to FormData for Lighthouse
    const formData = new FormData()
    const files = fs.getFiles()
    
    // Use Array.from to iterate over Map entries
    Array.from(files.entries()).forEach(([path, file]) => {
      formData.append('file', file, path)
    })

    // Upload using Lighthouse SDK with correct parameters
    const uploadResult = await lighthouse.upload(formData, LIGHTHOUSE_API_KEY)
    const cid = uploadResult.data.Hash

    onProgress?.({
      stage: 'uploading',
      progress: 90,
      message: 'Updating metadata with final CID...'
    })

    // Now update metadata with real CID and re-upload if needed
    const finalMetadata = generateMemoryMetadata(uploadData, cid)
    const finalMetadataJson = createMetadataFile(finalMetadata)
    
    // For simplicity in demo, we'll use the first upload's CID
    // In production, you might want to upload again with corrected metadata

    onProgress?.({
      stage: 'complete',
      progress: 100,
      message: 'Memory successfully uploaded to IPFS!'
    })

    const result: UploadResult = {
      success: true,
      cid,
      ipfsUrl: `ipfs://${cid}`,
      gatewayUrl: `https://gateway.lighthouse.storage/ipfs/${cid}`,
      metadataUrl: `ipfs://${cid}/metadata.json`,
      sceneUrl: `ipfs://${cid}/scene.ply`
    }

    console.log('‚úÖ Memory upload complete:', result)
    return result

  } catch (error) {
    console.error('‚ùå Error uploading memory:', error)
    
    onProgress?.({
      stage: 'error',
      progress: 0,
      message: 'Upload failed',
      error: error instanceof Error ? error.message : 'Unknown error'
    })

    return {
      success: false,
      error: error instanceof Error ? error.message : 'Upload failed'
    }
  } finally {
    fs.clear()
  }
}

// Utility function to trigger Filecoin storage deal (from original upload_memory.js)
export async function triggerFilecoinDeal(cid: string): Promise<boolean> {
  try {
    const response = await fetch('https://api.lighthouse.storage/api/v0/deal/request', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${LIGHTHOUSE_API_KEY}`
      },
      body: JSON.stringify({ cid })
    })

    if (!response.ok) {
      throw new Error(`HTTP error! status: ${response.status}`)
    }

    const dealData = await response.json()
    console.log('üìù Filecoin deal triggered:', dealData)
    return true
  } catch (error) {
    console.error('‚ùå Error triggering Filecoin deal:', error)
    return false
  }
}

// Get file URLs from IPFS CID
export function getMemoryFileUrls(cid: string) {
  const baseUrl = `https://gateway.lighthouse.storage/ipfs/${cid}`
  return {
    metadata: `${baseUrl}/metadata.json`,
    scene: `${baseUrl}/scene.ply`,
    preview: `${baseUrl}/preview.png`,
    text: `${baseUrl}/memory.txt`,
    gateway: baseUrl,
    ipfs: `ipfs://${cid}`
  }
} 